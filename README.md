# Crime-Category-Forecasting

# Overview
This dataset offers a comprehensive snapshot of criminal activities within the city. It encompasses various aspects of each incident, including date, time, location, victim demographics, and more.

By leveraging machine learning techniques, participants can analyze this rich dataset to predict crime categories, enhance law enforcement strategies, and bolster public safety measures.

My task is straightforward: Develop models capable of accurately predicting the crime categories based on this information.

# ðŸš€ Project Overview ðŸš€

**In my latest project, I tackled the challenge of predicting user ratings of food in restaurants. Leveraging a comprehensive workflow, I conducted a thorough data overview, delved into exploratory data analysis (EDA), and rigorously cleaned and preprocessed the dataset.**

- Comprehensive Workflow: Carried out a detailed project workflow that included data overview, exploratory data analysis (EDA), and rigorous data cleaning and preprocessing.
- Data Preprocessing: Applied Simple Imputer for filling missing values. Used StandardScaler and MinMaxScaler for scaling numerical data. Leveraged Pipeline and Column Transformer API for efficient processing.  
- Data Balancing: Implemented SMOTE API to balance the dataset.
  
# Project Structure
1. Jupyter Notebook
   - Contains the entire workflow of the project, including data loading, preprocessing, model training, evaluation, and visualization of results.
   - The notebook is available in **21f3002445_crime_predition.ipynb**
  

# Model Development: 
Created a classification model utilizing Logistic Regression, SVM, Perceptron, and ensemble methods, and Xgboost achieving up to 94.9% accuracy

# Performance Optimization: 
Applied feature engineering and hyperparameter tuning techniques to maximize model accuracy.

# Models Evaluated:
1. **Logistic regression**
   - Accuracy 93.5%
2. **Decision Tree**
   - Accuracy 92.9%
3. **SVC**
   - Accuracy 94.1%
4. **Random Forest**
   - Accuracy 93.8%
5.**LightGBM**
   - Accurcay 94.9%
  
# Technologies Used
   - Python: The primary programming language used for data manipulation and model training.
   - Jupyter Notebook: For interactive coding and documenting the workflow.
   - Pandas: For data loading and preprocessing.
   - Scikit-learn: For model training and evaluation.
   - Seaborn and Matplotlib: For data visualization and plotting model comparison graphs.

# Achievement: 
Secured 10th rank in a Kaggle competition
# Contact Information
- **Name:** Amit Kumar
- **LinkedIn:** [Amit Kumar](https://www.linkedin.com/in/amit-kumar83/)
Feel free to reach out for any queries or further information regarding the project.

